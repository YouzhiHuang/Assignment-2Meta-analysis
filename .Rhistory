xlab = "Z-Transformed Correlation Coefficient (Zr)",transfm = "none",legend.pos= "none")+
annotate(geom="text", x= 1.5, y= 13.2, label= paste0("italic(I)^{2} == ", round(i2_vals[1],1)),
color="black", parse = TRUE, size = 4)+
annotate(geom="text", x= 0.8, y= 5.2, label= paste0("95% prediction = ", round(predict(MLMA)[[5]],2)," to ", round(predict(MLMA)[[6]],2)))+
scale_y_discrete(limits = c(-4, 4))
p2 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transf = "tanh",k=F,g=F)+
annotate(geom="text", x= 1.3, y= 0.5, label= paste0("95% confidence = ", round(MLMA$ci.lb,2)," to ", round(MLMA$ci.ub,2)))
p1/p2
# Make an orchard plot using the model object
p1 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transfm = "none",legend.pos= "none")+
annotate(geom="text", x= 1.5, y= 13.2, label= paste0("italic(I)^{2} == ", round(i2_vals[1],1)),
color="black", parse = TRUE, size = 4)+
annotate(geom="text", x= 0.8, y= 5.2, label= paste0("95% prediction = ", round(predict(MLMA)[[5]],2)," ~ ", round(predict(MLMA)[[6]],2)))+
scale_y_discrete(limits = c(-4, 4))
p2 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transf = "tanh",k=F,g=F)+
annotate(geom="text", x= 1.3, y= 0.5, label= paste0("95% confidence = ", round(MLMA$ci.lb,2)," ~ ", round(MLMA$ci.ub,2)))+
annotate(geom="text", x= 0.9, y= 0.5, label= paste0("mean estimate = " ,round(MLMA$estimate,2)))
# Make an orchard plot using the model object
p1 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transfm = "none",legend.pos= "none")+
annotate(geom="text", x= 1.5, y= 13.2, label= paste0("italic(I)^{2} == ", round(i2_vals[1],1)),
color="black", parse = TRUE, size = 4)+
annotate(geom="text", x= 0.8, y= 5.2, label= paste0("95% prediction = ", round(predict(MLMA)[[5]],2)," ~ ", round(predict(MLMA)[[6]],2)))+
scale_y_discrete(limits = c(-4, 4))
p2 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transf = "tanh",k=F,g=F)+
annotate(geom="text", x= 1.3, y= 0.5, label= paste0("95% confidence = ", round(MLMA$ci.lb,2)," ~ ", round(MLMA$ci.ub,2)))+
annotate(geom="text", x= 0.9, y= 0.5, label= paste0("mean estimate = " ,round(MLMA$estimate, 2)))
# Make an orchard plot using the model object
p1 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transfm = "none",legend.pos= "none")+
annotate(geom="text", x= 1.5, y= 13.2, label= paste0("italic(I)^{2} == ", round(i2_vals[1],1)),
color="black", parse = TRUE, size = 4)+
annotate(geom="text", x= 0.8, y= 5.2, label= paste0("95% prediction = ", round(predict(MLMA)[[5]],2)," ~ ", round(predict(MLMA)[[6]],2)))+
scale_y_discrete(limits = c(-4, 4))
p2 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transf = "tanh",k=F,g=F)+
annotate(geom="text", x= 1.3, y= 0.5, label= paste0("95% confidence = ", round(MLMA$ci.lb,2)," ~ ", round(MLMA$ci.ub,2)))+
annotate(geom="text", x= 0.9, y= 0.5, label= paste0("mean estimate = " ,round(MLMA$estimate,2)))
# Calculate the prediction intervals
pis <- predict(MLMA)
pis
tr(MLMA)
# Calculate the prediction intervals
pis <- predict(MLMA)
pis
str(MLMA)
# Calculate the prediction intervals
pis <- predict(MLMA)
pis
str(MLMA)
# Make an orchard plot using the model object
p1 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transfm = "none",legend.pos= "none")+
annotate(geom="text", x= 1.5, y= 13.2, label= paste0("italic(I)^{2} == ", round(i2_vals[1],1)),
color="black", parse = TRUE, size = 4)+
annotate(geom="text", x= 0.8, y= 5.2, label= paste0("95% prediction = ", round(predict(MLMA)[[5]],2)," ~ ", round(predict(MLMA)[[6]],2)))+
scale_y_discrete(limits = c(-4, 4))
p2 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transf = "tanh",k=F,g=F)+
annotate(geom="text", x= 1.3, y= 0.5, label= paste0("95% confidence = ", round(MLMA$ci.lb,2)," ~ ", round(MLMA$ci.ub,2)))+
annotate(geom="text", x= 0.9, y= 0.5, label= paste0("mean estimate = " ,round(MLMA$b,2)))
p1/p2
# Make an orchard plot using the model object
p1 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transfm = "none",legend.pos= "none")+
annotate(geom="text", x= 1.5, y= 13.2, label= paste0("italic(I)^{2} == ", round(i2_vals[1],1)),
color="black", parse = TRUE, size = 4)+
annotate(geom="text", x= 0.8, y= 5.2, label= paste0("95% prediction = ", round(predict(MLMA)[[5]],2)," ~ ", round(predict(MLMA)[[6]],2)))+
scale_y_discrete(limits = c(-4, 4))
p2 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transf = "tanh",k=F,g=F)+
annotate(geom="text", x= 1.3, y= 0.5, label= paste0("95% confidence = ", round(MLMA$ci.lb,2)," ~ ", round(MLMA$ci.ub,2)))+
annotate(geom="text", x= 0.8, y= 0.5, label= paste0("mean estimate = " ,round(MLMA$b,2)))
p1/p2
# Make an orchard plot using the model object
p1 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transfm = "none",legend.pos= "none")+
annotate(geom="text", x= 1.5, y= 13.2, label= paste0("italic(I)^{2} == ", round(i2_vals[1],1)),
color="black", parse = TRUE, size = 4)+
annotate(geom="text", x= 0.8, y= 5.2, label= paste0("95% prediction = ", round(predict(MLMA)[[5]],2)," ~ ", round(predict(MLMA)[[6]],2)))+
scale_y_discrete(limits = c(-4, 4))
p2 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Z-Transformed Correlation Coefficient (Zr)",transf = "tanh",k=F,g=F)+
annotate(geom="text", x= 1.3, y= 0.5, label= paste0("95% confidence = ", round(MLMA$ci.lb,2)," ~ ", round(MLMA$ci.ub,2)))+
annotate(geom="text", x= 0.8, y= 0.5, label= paste0("Mean estimate = " ,round(MLMA$b,2)))
p1/p2
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, color=Study)) +
geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = T)+
geom_point(size=InRRdata$Average_n*0.03,alpha = 0.3) +
#scale_size(range = c(1, 2), name="Sample size")+
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)+
theme(legend.position = "none")
Time_lag
# Lets make a funnel plot to visualize the data in relation to the precision,
# inverse sampling standard error,
funnel<-ggplot(InRRdata,aes(x=lnRR, y=Average_n, color=Study))+
geom_point(size=2,alpha=0.6)+
scale_color_viridis(discrete=TRUE)+
xlab("Effect size magitude (lnRR)")+
ylab("Mean sample size")+
scale_x_continuous(breaks = round(seq(min(InRRdata$lnRR), max(InRRdata$lnRR), by = 1),0))+
scale_y_continuous(breaks = round(seq(0, 600, by = 50),1))+
theme(legend.position = "NONE")+
geom_vline(xintercept =0,linetype="dashed",color="red")+
theme_bw(12)+
theme(legend.position = "NONE")+
theme(panel.grid.minor = element_blank())
funnel
ggplot(InRRdata, aes(y = lnRR, x = V_lnRR)) + geom_point() + geom_smooth(method = lm) +
labs(y = "Fisher's Z-transformed Correlation Coefficient (Zr)", x = "Sampling Variance of Zr") +
theme_classic()
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, color=Study)) +
geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = T)+
geom_point(size=InRRdata$Average_n*0.03,alpha = 0.3) +
#scale_size(range = c(1, 2), name="Sample size")+
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)+
theme(legend.position = "none")
Time_lag
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, color=Study)) +
geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = T)+
geom_point(size=InRRdata$Average_n*0.03,alpha = 0.3) +
#scale_size(range = c(1, 2), name="Sample size")+
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)+
theme(legend.position = "none")
Time_lag
knitr::opts_chunk$set(echo = TRUE)
options(digits=3)
# Install a load of packages that we'll use.
library(pacman)
p_load(bookdown, devtools, tidyverse, ggforce, GGally, flextable, latex2exp, png, magick, metafor, MASS, emmeans, R.rsp,viridis,patchwork)
# Install the orchaRd package
# devtools::install_github("daniel1noble/orchaRd", force = TRUE)
library(orchaRd)
# Load data file from the data folder
path <- "./data/OA_activitydat_20190302_BIOL3207.csv"
data <- read_csv(path)
# Code to removing missing data
comp_data <-  data %>% drop_na()
# Drop irrelevant columns
Sp_Tr <- comp_data %>% dplyr::select(-c(...1,comment,loc,animal_id,sl,size))
# Check spelling in species and treatment but also generate a summary table
unique(Sp_Tr$species)
unique(Sp_Tr$treatment)
# Use flextable to render the summary table in a tidy format
use_df_printer()
set_flextable_defaults(
theme_fun = theme_booktabs,
big.mark = " ",
font.color = "#666666",
border.color = "#666666",
padding = 3,
)
# Create a summary of the original dataset.
dat <- Sp_Tr %>%
group_by(treatment,species) %>%
summarise(n=n(),
across(
where(is.numeric),
.fns = list(
avg = ~ mean(.x, na.rm = TRUE),
sd = ~ sd(.x, na.rm = TRUE)
)
),.groups = "drop" ) %>%
subset(select=-c(n_avg,n_sd))
fdata <-  as_tibble(dat)
# Use flextable to render the summary table
ft <-  fdata%>%
flextable() %>%
separate_header() %>%
merge_v(j = c("treatment","species")) %>%
theme_booktabs(bold_header = TRUE)  %>%
valign(j = 1, valign = "top") %>%
align(align = "center", part = "all", j = 4:5)%>%
colformat_double(digits = 2)  %>%
autofit()   %>%
footnote(i = 2, j = grep("avg", colnames(fdata), value = TRUE),
part = "header",
ref_symbols = " ",
value = as_paragraph("avg: Arithmetic Mean")) %>%
footnote(i = 2, j = grep("sd", colnames(fdata), value = TRUE),
part = "header",
ref_symbols = " ", value = as_paragraph("sd: Standard Deviation"))
ft
# Load data file from the data folder
matadata <- read_csv("./data/clark_paper_data.csv")
# Turn and statistics into wide data for merging
wider <- pivot_wider(fdata,names_from = treatment, values_from = c(n,activity_avg,activity_sd))
names(wider) <- c("Species","oa.n","ctrl.n","oa.mean","ctrl.mean","oa.sd","ctrl.sd")
# Repeat metadata to accommodate statistics
matadatarep <- matadata[rep(seq_len(nrow(matadata)),each=6),]
# Merge them and look at the result
meta_clark <- bind_cols(matadatarep,wider)
meta_clark
ocean_matadata <- read_csv("./data/ocean_meta_data.csv")
oceanmatadata <- merge(x = ocean_matadata, y = meta_clark, all = TRUE)
oceanmatadata
# Rebuild the variable name avoiding spaces
names(oceanmatadata)[3:4] <- c("Year_online","Year_print")
names(oceanmatadata)[7:10] <- c("Pub_year_IF","2017_IF","Average_n","Effect_type")
names(oceanmatadata)[12:16] <- c("Climate_FishBase","Env_cue/stimulus?","Cue/stimulus_type","Behavioural_metric","Life_stage")
# check spell
unique(sort(oceanmatadata$Species))
oceanmatadata$Species[oceanmatadata$Species == "acantho"] <- "Acanthochromis polyacanthus"
oceanmatadata$Species[oceanmatadata$Species == "ambon"] <- "Pomacentrus amboinensis"
oceanmatadata$Species[oceanmatadata$Species == "chromis"] <- "Chromis atripectoralis"
oceanmatadata$Species[oceanmatadata$Species == "humbug"] <- "Dascyllus aruanus"
oceanmatadata$Species[oceanmatadata$Species == "lemon"] <- "Pomacentrus moluccensis"
oceanmatadata$Species[oceanmatadata$Species == "whitedams"] <- "Dischistodus perspicillatus"
summary(oceanmatadata)
View(oceanmatadata)
View(InRRdata)
#Multi-level meta-analytic model
MLMA <- metafor::rma.mv(lnRR  ~ 1, V = V_lnRR, method = "REML", random=list( ~1|Study,~1|Observation),test = "t",data=InRRdata)
MLMA
#Multi-level meta-analytic model
MLMA <- metafor::rma.mv(lnRR  ~ 1, V = V_lnRR, method = "REML", random=list( ~1|Study,~1|Observation),test = "t",data=InRRdata)
MLMA
# variation does time when results were published explain in lnRR
r2_time <- orchaRd::r2_ml(metareg_time)
r2_time
# variation does time when results were published explain in lnRR
r2_time <- orchaRd::r2_ml(metareg_time)
r2 <- tibble(r2_time)
r2
# variation does time when results were published explain in lnRR
r2_time <- orchaRd::r2_ml(metareg_time)
r2 <- as.tibble(r2_time)
r2
# variation does time when results were published explain in lnRR
r2_time <- orchaRd::r2_ml(metareg_time)
r2 <- as_tibble(r2_time)
r2
# Including sampling variance as moderators to account for both!
metareg_time2 <- rma.mv(lnRR ~ 1/V_lnRR ,  V = V_lnRR,random = list(~1 |Study, ~1 | Observation),
test = "t", dfs = "contain", data = nInRRdata)
summary(metareg_time2)
r2_time2 <- orchaRd::r2_ml(metareg_time2)
r2_time2
# Including sampling variance as moderators to account for both!
metareg_time2 <- rma.mv(lnRR ~ 1/V_lnRR ,  V = V_lnRR,random = list(~1 |Study, ~1 | Observation),
test = "t", dfs = "contain", data = InRRdata)
summary(metareg_time2)
r2_time2 <- orchaRd::r2_ml(metareg_time2)
r2_time2
InRRdata <- InRRdata %>%
mutate(Year_c = Year_online - mean(Year_online))
# Including sampling variance and mean centered year as moderators to account for both
metareg_time_c <- rma.mv(lnRR ~ Year_c + V_lnRR,  V = V_lnRR,random = list(~1 |Study, ~1 | Observation),
test = "t", dfs = "contain", data = InRRdata)
summary(metareg_time_c)
InRRdata <- InRRdata %>%
mutate(Year_c = Year_online - mean(Year_online))
# Including sampling variance and mean centered year as moderators to account for both
metareg_time_c <- rma.mv(lnRR ~ Year_c + V_lnRR,  V = V_lnRR,random = list(~1 |Study, ~1 | Observation),
test = "t", dfs = "contain", data = InRRdata)
summary(metareg_time_c)
r2_timec <- orchaRd::r2_ml(metareg_time_c)
r2_timec
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
taf <- trimfill(MLMA)
funnel(funnel)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
taf <- trimfill(MLMA)
funnel(funnel)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
res <- rma(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, data=nInRRdata, measure="OR")
taf <- trimfill(res)
funnel(funnel)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
res <- rma(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",data=nInRRdata, measure="OR")
taf <- trimfill(res)
funnel(funnel)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
res <- rma(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",data=nInRRdata, measure="OR")
taf <- trimfill(res)
funnel(funnel)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
res <- rma(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR,data=nInRRdata, measure="OR")
taf <- trimfill(res)
funnel(taf)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
res <- rma(yi = nInRRdata$lnRR, vi = nInRRdata$V_lnRR,data=nInRRdata, measure="OR")
taf <- trimfill(res)
funnel(taf)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
res <- rma(yi = nInRRdata$lnRR, vi = nInRRdata$V_lnRR,data=nInRRdata, measure="OR")
taf <- trimfill(res)
funnel(taf,yaxis="vi")
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, size=InRRdata$Average_n*0.05)) +
geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = F)+
geom_point(aes(color= Study), show.legend = F) +
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
labs(size = "Precision (N)")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)
Time_lag
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, size=InRRdata$Average_n*0.05)) +
geom_smooth(aes(alpha=0.05),method = "loess", fullrange=TRUE, level=0.95, color="black",show.legend = F)+
geom_point(aes(color= Study), show.legend = F) +
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
labs(size = "Precision (N)")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)
Time_lag
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, size=((InRRdata$Average_n)^3)*0.05)) +
geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = F)+
geom_point(aes(color= Study), show.legend = F) +
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
labs(size = "Precision (N)")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)
Time_lag
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, size=((InRRdata$Average_n)^4)*0.06)) +
geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = F)+
geom_point(aes(color= Study), show.legend = F) +
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
labs(size = "Precision (N)")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)
Time_lag
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, size=((InRRdata$Average_n)^6)*0.06)) +
geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = F)+
geom_point(aes(color= Study), show.legend = F) +
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
labs(size = "Precision (N)")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)
Time_lag
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, size=((InRRdata$Average_n)^6)*0.08)) +
geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = F)+
geom_point(aes(color= Study), show.legend = F) +
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
labs(size = "Precision (N)")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)
Time_lag
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, size=((InRRdata$Average_n)^5)*0.06)) +
geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = F)+
geom_point(aes(color= Study), show.legend = F) +
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
labs(size = "Precision (N)")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)
Time_lag
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, size=((InRRdata$Average_n)^5)*0.06)) +
geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = F)+
geom_point(aes(color= InRRdata$Study), show.legend = F) +
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
labs(size = "Precision (N)")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)
Time_lag
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 10)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 5)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 4)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 3)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 2)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 10)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 100)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
funnel<- ggplot(nInRRdata,aes(x = lnRR, y= V_lnRR, color=Study))+
geom_point(size=2,alpha=0.6)+
scale_color_viridis(discrete=TRUE)+
xlab("Effect size magitude (lnRR)")+
ylab("Variance(V_lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$lnRR), max(InRRdata$lnRR), by = 1),0))+
ylim(c(0,20))+
scale_y_continuous(breaks = round(seq(0, 50, by = 5),1))+
theme(legend.position = "NONE")+
geom_vline(xintercept =0,linetype="dashed",color="red")+
theme_bw(12)+
theme(legend.position = "NONE")+
theme(panel.grid.minor = element_blank())
funnel
funnel<- ggplot(nInRRdata,aes(x = lnRR, y= V_lnRR, color=Study))+
geom_point(size=1,alpha=0.6)+
scale_color_viridis(discrete=TRUE)+
xlab("Effect size magitude (lnRR)")+
ylab("Variance(V_lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$lnRR), max(InRRdata$lnRR), by = 1),0))+
ylim(c(0,20))+
scale_y_continuous(breaks = round(seq(0, 50, by = 5),1))+
theme(legend.position = "NONE")+
geom_vline(xintercept =0,linetype="dashed",color="red")+
theme_bw(12)+
theme(legend.position = "NONE")+
theme(panel.grid.minor = element_blank())
funnel
funnel<- ggplot(nInRRdata,aes(x = lnRR, y= V_lnRR, color=Study))+
geom_point(size=1.5,alpha=0.6)+
scale_color_viridis(discrete=TRUE)+
xlab("Effect size magitude (lnRR)")+
ylab("Variance(V_lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$lnRR), max(InRRdata$lnRR), by = 1),0))+
ylim(c(0,20))+
scale_y_continuous(breaks = round(seq(0, 50, by = 5),1))+
theme(legend.position = "NONE")+
geom_vline(xintercept =0,linetype="dashed",color="red")+
theme_bw(12)+
theme(legend.position = "NONE")+
theme(panel.grid.minor = element_blank())
funnel
funnel<- ggplot(nInRRdata,aes(x = lnRR, y= V_lnRR, color=Study))+
geom_point(size=1.2,alpha=0.6)+
scale_color_viridis(discrete=TRUE)+
xlab("Effect size magitude (lnRR)")+
ylab("Variance(V_lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$lnRR), max(InRRdata$lnRR), by = 1),0))+
ylim(c(0,20))+
scale_y_continuous(breaks = round(seq(0, 50, by = 5),1))+
theme(legend.position = "NONE")+
geom_vline(xintercept =0,linetype="dashed",color="red")+
theme_bw(12)+
theme(legend.position = "NONE")+
theme(panel.grid.minor = element_blank())
funnel
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, size=((InRRdata$Average_n)^5)*0.06)) +
geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = F)+
geom_point(aes(color= InRRdata$Study), show.legend = F) +
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
labs(size = "Precision (N)")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)
Time_lag
# time variation explain results were published in lnRR
r2_time <- orchaRd::r2_ml(metareg_time)
r2_time
summary(metareg_time)
# time variation explain results were published in lnRR
r2_time <- orchaRd::r2_ml(metareg_time)
# Make a pretty table. First, lets clean up the names of the different I2 estimates. Lets remove I2_. It's a string, so, we can use some regular expressions to fix that. `gsub` is pretty useful. You put a pattern in and tell it what you would like to replace the text with. In this case, just blank will do! Then, we'll make the first letter of what is left capitalised.
r2_tim <- tibble(type = firstup(gsub("I2_", "", names(r2_time))), I2 = r2_time)
# Now, lets make a pretty table. We can so some nice modifications here too.
flextable(r2_tim) %>%
align(part = "header", align = "center")
r2_tim
