summary(metareg_time_c)
r2_timec <- orchaRd::r2_ml(metareg_time_c)
r2_timec
# Use flextable to render the summary table in a tidy format
use_df_printer()
set_flextable_defaults(
theme_fun = theme_booktabs,
big.mark = " ",
font.color = "#666666",
border.color = "#666666",
padding = 3,
)
# Create a summary of the original dataset.
dat <- Sp_Tr %>%
group_by(treatment,species) %>%
summarise(n=n(),
across(
where(is.numeric),
.fns = list(
avg = ~ mean(.x, na.rm = TRUE),
sd = ~ sd(.x, na.rm = TRUE)
)
),.groups = "drop" ) %>%
subset(select=-c(n_avg,n_sd))
fdata <-  as_tibble(dat)
# Use flextable to render the summary table
ft <-  fdata%>%
flextable() %>%
separate_header() %>%
merge_v(j = c("treatment","species")) %>%
theme_booktabs(bold_header = TRUE)  %>%
valign(j = 1, valign = "top") %>%
align(align = "center", part = "all", j = 4:5)%>%
colformat_double(digits = 2)  %>%
autofit()   %>%
footnote(i = 2, j = grep("avg", colnames(fdata), value = TRUE),
part = "header",
ref_symbols = " ",
value = as_paragraph("avg: Arithmetic Mean")) %>%
footnote(i = 2, j = grep("sd", colnames(fdata), value = TRUE),
part = "header",
ref_symbols = " ", value = as_paragraph("sd: Standard Deviation"))
ft
# Rebuild the variable name avoiding spaces
names(oceanmatadata)[3:4] <- c("Year_online","Year_print")
names(oceanmatadata)[7:10] <- c("Pub_year_IF","2017_IF","Average_n","Effect_type")
names(oceanmatadata)[12:16] <- c("Climate_FishBase","Env_cue/stimulus?","Cue/stimulus_type","Behavioural_metric","Life_stage")
# Correct all the variables type
oceanmatadata$Pub_year_IF <- as.numeric(oceanmatadata$Pub_year_IF)
oceanmatadata$`2017_IF` <- as.numeric(oceanmatadata$`2017_IF`)
# check spell
unique(sort(oceanmatadata$Species))
# Rebuild the variable name avoiding spaces
names(oceanmatadata)[3:4] <- c("Year_online","Year_print")
names(oceanmatadata)[7:10] <- c("Pub_year_IF","IF_2017","Average_n","Effect_type")
names(oceanmatadata)[12:16] <- c("Climate_FishBase","Env_cue/stimulus?","Cue/stimulus_type","Behavioural_metric","Life_stage")
# Correct all the variables type
oceanmatadata$Pub_year_IF <- as.numeric(oceanmatadata$Pub_year_IF)
oceanmatadata$IF_2017 <- as.numeric(oceanmatadata$IF_2017)
# check spell
unique(sort(oceanmatadata$Species))
# Rebuild the variable name avoiding spaces
names(oceanmatadata)[3:4] <- c("Year_online","Year_print")
names(oceanmatadata)[7:10] <- c("Pub_year_IF","IF_2017","Average_n","Effect_type")
names(oceanmatadata)[12:16] <- c("Climate_FishBase","Env_cue/stimulus?","Cue/stimulus_type","Behavioural_metric","Life_stage")
# Correct all the variables type
oceanmatadata$Pub_year_IF <- as.numeric(oceanmatadata$Pub_year_IF)
oceanmatadata$IF_2017 <- as.numeric(oceanmatadata$IF_2017)
# check spell
unique(sort(oceanmatadata$Species))
# Install a load of packages that we'll use.
library(pacman)
p_load(bookdown, devtools, tidyverse, ggforce, GGally, flextable, latex2exp, png, magick, metafor, MASS, emmeans, R.rsp,viridis,patchwork)
# Install the orchaRd package
# devtools::install_github("daniel1noble/orchaRd", force = TRUE)
library(orchaRd)
# Load data file from the data folder
path <- "./data/OA_activitydat_20190302_BIOL3207.csv"
data <- read_csv(path)
# Code to removing missing data
comp_data <-  data %>% drop_na()
# Drop irrelevant columns
Sp_Tr <- comp_data %>% dplyr::select(-c(...1,comment,loc,animal_id,sl,size))
# Check spelling in species and treatment but also generate a summary table
unique(Sp_Tr$species)
unique(Sp_Tr$treatment)
# Use flextable to render the summary table in a tidy format
use_df_printer()
set_flextable_defaults(
theme_fun = theme_booktabs,
big.mark = " ",
font.color = "#666666",
border.color = "#666666",
padding = 3,
)
# Create a summary of the original dataset.
dat <- Sp_Tr %>%
group_by(treatment,species) %>%
summarise(n=n(),
across(
where(is.numeric),
.fns = list(
avg = ~ mean(.x, na.rm = TRUE),
sd = ~ sd(.x, na.rm = TRUE)
)
),.groups = "drop" ) %>%
subset(select=-c(n_avg,n_sd))
fdata <-  as_tibble(dat)
# Use flextable to render the summary table
ft <-  fdata%>%
flextable() %>%
separate_header() %>%
merge_v(j = c("treatment","species")) %>%
theme_booktabs(bold_header = TRUE)  %>%
valign(j = 1, valign = "top") %>%
align(align = "center", part = "all", j = 4:5)%>%
colformat_double(digits = 2)  %>%
autofit()   %>%
footnote(i = 2, j = grep("avg", colnames(fdata), value = TRUE),
part = "header",
ref_symbols = " ",
value = as_paragraph("avg: Arithmetic Mean")) %>%
footnote(i = 2, j = grep("sd", colnames(fdata), value = TRUE),
part = "header",
ref_symbols = " ", value = as_paragraph("sd: Standard Deviation"))
ft
# Load data file from the data folder
matadata <- read_csv("./data/clark_paper_data.csv")
# Turn and statistics into wide data for merging
wider <- pivot_wider(fdata,names_from = treatment, values_from = c(n,activity_avg,activity_sd))
names(wider) <- c("Species","oa.n","ctrl.n","oa.mean","ctrl.mean","oa.sd","ctrl.sd")
# Repeat metadata to accommodate statistics
matadatarep <- matadata[rep(seq_len(nrow(matadata)),each=6),]
# Merge them and look at the result
meta_clark <- bind_cols(matadatarep,wider)
meta_clark
ocean_matadata <- read_csv("./data/ocean_meta_data.csv")
oceanmatadata <- merge(x = ocean_matadata, y = meta_clark, all = TRUE)
oceanmatadata
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Chunk 1: setup
knitr::opts_chunk$set(echo = TRUE)
options(digits=3)
# Chunk 2: loadpacks
# Install a load of packages that we'll use.
library(pacman)
p_load(bookdown, devtools, tidyverse, ggforce, GGally, flextable, latex2exp, png, magick, metafor, MASS, emmeans, R.rsp,viridis,patchwork)
# Install the orchaRd package
# devtools::install_github("daniel1noble/orchaRd", force = TRUE)
library(orchaRd)
# Chunk 3: datalaod
# Load data file from the data folder
path <- "./data/OA_activitydat_20190302_BIOL3207.csv"
data <- read_csv(path)
# Chunk 4: Data wrangling
# Code to removing missing data
comp_data <-  data %>% drop_na()
# Drop irrelevant columns
Sp_Tr <- comp_data %>% dplyr::select(-c(...1,comment,loc,animal_id,sl,size))
# Check spelling in species and treatment but also generate a summary table
unique(Sp_Tr$species)
unique(Sp_Tr$treatment)
# Chunk 5: Calculate and visualise statistics
# Use flextable to render the summary table in a tidy format
use_df_printer()
set_flextable_defaults(
theme_fun = theme_booktabs,
big.mark = " ",
font.color = "#666666",
border.color = "#666666",
padding = 3,
)
# Create a summary of the original dataset.
dat <- Sp_Tr %>%
group_by(treatment,species) %>%
summarise(n=n(),
across(
where(is.numeric),
.fns = list(
avg = ~ mean(.x, na.rm = TRUE),
sd = ~ sd(.x, na.rm = TRUE)
)
),.groups = "drop" ) %>%
subset(select=-c(n_avg,n_sd))
fdata <-  as_tibble(dat)
# Use flextable to render the summary table
ft <-  fdata%>%
flextable() %>%
separate_header() %>%
merge_v(j = c("treatment","species")) %>%
theme_booktabs(bold_header = TRUE)  %>%
valign(j = 1, valign = "top") %>%
align(align = "center", part = "all", j = 4:5)%>%
colformat_double(digits = 2)  %>%
autofit()   %>%
footnote(i = 2, j = grep("avg", colnames(fdata), value = TRUE),
part = "header",
ref_symbols = " ",
value = as_paragraph("avg: Arithmetic Mean")) %>%
footnote(i = 2, j = grep("sd", colnames(fdata), value = TRUE),
part = "header",
ref_symbols = " ", value = as_paragraph("sd: Standard Deviation"))
ft
# Chunk 6: load metadata
# Load data file from the data folder
matadata <- read_csv("./data/clark_paper_data.csv")
# Chunk 7: clarkdata wrangling
# Turn and statistics into wide data for merging
wider <- pivot_wider(fdata,names_from = treatment, values_from = c(n,activity_avg,activity_sd))
names(wider) <- c("Species","oa.n","ctrl.n","oa.mean","ctrl.mean","oa.sd","ctrl.sd")
# Repeat metadata to accommodate statistics
matadatarep <- matadata[rep(seq_len(nrow(matadata)),each=6),]
# Merge them and look at the result
meta_clark <- bind_cols(matadatarep,wider)
meta_clark
# Chunk 8: load ocean metadata
ocean_matadata <- read_csv("./data/ocean_meta_data.csv")
# Chunk 9: Merge two metadata
oceanmatadata <- merge(x = ocean_matadata, y = meta_clark, all = TRUE)
oceanmatadata
# Chunk 10: metadata wrangling-name
# Rebuild the variable name avoiding spaces
names(oceanmatadata)[3:4] <- c("Year_online","Year_print")
names(oceanmatadata)[7:10] <- c("Pub_year_IF","IF_2017","Average_n","Effect_type")
names(oceanmatadata)[12:16] <- c("Climate_FishBase","Env_cue/stimulus?","Cue/stimulus_type","Behavioural_metric","Life_stage")
# Correct all the variables type
oceanmatadata$Pub_year_IF <- as.numeric(oceanmatadata$Pub_year_IF)
oceanmatadata$IF_2017 <- as.numeric(oceanmatadata$IF_2017)
# check spell
unique(sort(oceanmatadata$Species))
# Chunk 11: metadata wrangling-spell
oceanmatadata$Species[oceanmatadata$Species == "acantho"] <- "Acanthochromis polyacanthus"
oceanmatadata$Species[oceanmatadata$Species == "ambon"] <- "Pomacentrus amboinensis"
oceanmatadata$Species[oceanmatadata$Species == "chromis"] <- "Chromis atripectoralis"
oceanmatadata$Species[oceanmatadata$Species == "humbug"] <- "Dascyllus aruanus"
oceanmatadata$Species[oceanmatadata$Species == "lemon"] <- "Pomacentrus moluccensis"
oceanmatadata$Species[oceanmatadata$Species == "whitedams"] <- "Dischistodus perspicillatus"
summary(oceanmatadata)
# Chunk 12: lnRRfilter
# Exclude some NA's in sample size and r
cleanoceanmatadata <- oceanmatadata[complete.cases(oceanmatadata$ctrl.mean) & complete.cases(oceanmatadata$oa.mean)& complete.cases(oceanmatadata$ctrl.sd)& complete.cases(oceanmatadata$oa.sd)& complete.cases(oceanmatadata$ctrl.n)& complete.cases(oceanmatadata$oa.n),]
cleanInRRdata <- cleanoceanmatadata %>% filter(oa.mean/ctrl.mean >=0)
# Chunk 13: lnRRcalculated
InRRdata <-  metafor::escalc(measure="ROM", m1i=oa.mean,  m2i=ctrl.mean, sd1i=oa.sd, sd2i=ctrl.sd, n1i=oa.n, n2i=ctrl.n, data=cleanInRRdata,var.names = c("lnRR", "V_lnRR"))
# Chunk 14: 5.1
# Create a new `Observation` variable
InRRdata$Observation <- rep(1:nrow(InRRdata))
# Chunk 15: 5.2
#Multi-level meta-analytic model
MLMA <- metafor::rma.mv(lnRR  ~ 1, V = V_lnRR, method = "REML", random=list( ~1|Study,~1|Observation),test = "t",data=InRRdata)
# Chunk 16
MLMA
# Chunk 17: het
# Calculate I2
i2_vals <- orchaRd::i2_ml(MLMA)
# Make a pretty table. First, lets clean up the names of the different I2 estimates. Lets remove I2_. It's a string, so, we can use some regular expressions to fix that. `gsub` is pretty useful. You put a pattern in and tell it what you would like to replace the text with. In this case, just blank will do! Then, we'll make the first letter of what is left capitalised.
i2 <- tibble(type = firstup(gsub("I2_", "", names(i2_vals))), I2 = i2_vals)
# Now, lets make a pretty table. We can so some nice modifications here too.
flextable(i2) %>%
align(part = "header", align = "center") %>%
compose(part = "header", j = 1, value = as_paragraph(as_b("Type"))) %>%
compose(part = "header", j = 2, value = as_paragraph(as_b("I"), as_b(as_sup("2")),
as_b("(%)")))
# Chunk 18: pis
# Calculate the prediction intervals
pis <- predict(MLMA)
pis
# Chunk 19: fig1
# Make an orchard plot using the model object
p1 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "Effect size magnitude (lnRR)",transfm = "none",legend.pos= "none")+
annotate(geom="text", x= 1.5, y= 13.2, label= paste0("italic(I)^{2} == ", round(i2_vals[1],1)),
color="black", parse = TRUE, size = 4)+
annotate(geom="text", x= 0.8, y= 5.2, label= paste0("95% prediction = ", round(predict(MLMA)[[5]],2)," ~ ", round(predict(MLMA)[[6]],2)))+
scale_y_discrete(limits = c(-4, 4))
p2 <- orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
xlab = "A tanh transformation to effect size magnitude (lnRR)",transf = "tanh",k=F,g=F)+
annotate(geom="text", x= 1.3, y= 0.5, label= paste0("95% confidence = ", round(MLMA$ci.lb,2)," ~ ", round(MLMA$ci.ub,2)))+
annotate(geom="text", x= 0.8, y= 0.5, label= paste0("Mean estimate = " ,round(MLMA$b,2)))
p1/p2
# Chunk 20: fig2
# a caterpillar plot (not a caterpillars plot)
orchaRd::caterpillars(MLMA, group = "Study", data = InRRdata,
xlab = "A tanh transformation to effect size magnitude (lnRR)",transfm = "tanh")
# Chunk 21: fig3
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Chunk 22: fig4
funnel<- ggplot(nInRRdata,aes(x = lnRR, y= V_lnRR, color=Study))+
geom_point(size=1.2,alpha=0.6)+
scale_color_viridis(discrete=TRUE)+
xlab("Effect size magitude (lnRR)")+
ylab("Variance(V_lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$lnRR), max(InRRdata$lnRR), by = 1),0))+
ylim(c(0,20))+
scale_y_continuous(breaks = round(seq(0, 50, by = 5),1))+
theme(legend.position = "NONE")+
geom_vline(xintercept =0,linetype="dashed",color="red")+
theme_bw(12)+
theme(legend.position = "NONE")+
theme(panel.grid.minor = element_blank())
funnel
# Chunk 23
# Including sampling variance as moderator
metareg_v <- rma.mv(lnRR ~ V_lnRR, V = V_lnRR, random = list(~1 | Study, ~1 | Observation),
test = "t", dfs = "contain", data = nInRRdata)
summary(metareg_v)
r2 <- orchaRd::r2_ml(metareg_v)
r2
# Chunk 24: fig5
Time_lag <- ggplot(InRRdata, aes(y = lnRR, x = Year_online, size=((InRRdata$Average_n)^5)*0.06)) +
geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = F)+
geom_point(aes(color= InRRdata$Study), show.legend = F) +
scale_color_viridis(discrete=TRUE)+
geom_hline(yintercept =0,linetype="dashed",color="red")+
labs(size = "Precision (N)")+
xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)
Time_lag
# Chunk 25
# Including sampling variance as moderator
metareg_time <- rma.mv(lnRR ~ Year_online, V = V_lnRR, random = list(~1 |Study, ~1 | Observation),test = "t", dfs = "contain", data = InRRdata)
# Chunk 26
summary(metareg_time)
# Chunk 27: tab2
# time variation explain results were published in lnRR
r2_time <- orchaRd::r2_ml(metareg_time)
# Make a pretty table. First, lets clean up the names of the different I2 estimates. Lets remove I2_. It's a string, so, we can use some regular expressions to fix that. `gsub` is pretty useful. You put a pattern in and tell it what you would like to replace the text with. In this case, just blank will do! Then, we'll make the first letter of what is left capitalised.
r2_tim <- tibble(type = firstup(gsub("Percentage of variance in effect size", "", names(r2_time))),  Percentage= r2_time)
# Now, lets make a pretty table. We can so some nice modifications here too.
flextable(r2_tim) %>%
align(part = "header", align = "center")
# Chunk 28
# Including sampling variance as moderators
metareg_time2 <- rma.mv(lnRR ~ 1/V_lnRR ,  V = V_lnRR,random = list(~1 |Study, ~1 | Observation),
test = "t", dfs = "contain", data = InRRdata)
summary(metareg_time2)
r2_time2 <- orchaRd::r2_ml(metareg_time2)
r2_time2
# Chunk 29
# Including sampling variance and mean centered year as moderators to account for both
InRRdata <- InRRdata %>%
mutate(Year_c = Year_online - mean(Year_online))
metareg_time_c <- rma.mv(lnRR ~ Year_c + V_lnRR,  V = V_lnRR,random = list(~1 |Study, ~1 | Observation),
test = "t", dfs = "contain", data = InRRdata)
summary(metareg_time_c)
r2_timec <- orchaRd::r2_ml(metareg_time_c)
r2_timec
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
funnel<- ggplot(nInRRdata,aes(x = lnRR, y= V_lnRR, color=Study))+
geom_point(size=1.2,alpha=0.6)+
scale_color_viridis(discrete=TRUE)+
xlab("Effect size magitude (lnRR)")+
ylab("Variance(V_lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$lnRR), max(InRRdata$lnRR), by = 1),0))+
ylim(c(0,20))+
scale_y_continuous(breaks = round(seq(0, 50, by = 5),1))+
theme(legend.position = "NONE")+
geom_vline(xintercept =0,linetype="dashed",color="red")+
theme_bw(12)+
theme(legend.position = "NONE")+
theme(panel.grid.minor = element_blank())
funnel
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
funnel<- ggplot(nInRRdata,aes(x = lnRR, y= V_lnRR, color=Study))+
geom_point(size=1.2,alpha=0.6)+
scale_color_viridis(discrete=TRUE)+
xlab("Effect size magitude (lnRR)")+
ylab("Variance(V_lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$lnRR), max(InRRdata$lnRR), by = 1),0))+
ylim(c(0,20))+
scale_y_continuous(breaks = round(seq(0, 50, by = 5),1))+
theme(legend.position = "NONE")+
geom_vline(xintercept =0,linetype="dashed",color="red")+
theme_bw(12)+
theme(legend.position = "NONE")+
theme(panel.grid.minor = element_blank())
funnel
funnel<- ggplot(nInRRdata,aes(x = lnRR, y= V_lnRR, color=Study))+
geom_point(size=1.2,alpha=0.6)+
scale_color_viridis(discrete=TRUE)+
xlab("Effect size magitude (lnRR)")+
ylab("Variance(V_lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$lnRR), max(InRRdata$lnRR), by = 1),0))+
ylim(c(0,20))+
scale_y_continuous(breaks = round(seq(0, 50, by = 5),1))+
theme(legend.position = "NONE")+
geom_vline(xintercept =0,linetype="dashed",color="red")+
theme_bw(12)+
theme(legend.position = "NONE")+
theme(panel.grid.minor = element_blank())
funnel
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.1, 20), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0, 20), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0, 20), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.001, 20), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.001, 10), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.01, 10), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.1, 10), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.1, 5), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.1, 5),xlim = c(-4, 4), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.1, 30),xlim = c(-4, 4), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.01, 30),xlim = c(-4, 4), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.001, 30),xlim = c(-4, 4), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.001, 25),xlim = c(-4, 4), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
nInRRdata <- InRRdata%>%filter(V_lnRR <= 1000)
funnel1 <- metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="vi",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.001, 25),xlim = c(-4, 4), xlab = "Effect size magitude (lnRR)", legend = TRUE)
# Lets make a funnel plot to visualize the data in relation to the precision. Note that one sample that was an extreme outlier was removed in the paper
metafor::funnel(x = nInRRdata$lnRR, vi = nInRRdata$V_lnRR, yaxis="seinv",
digits = 2, level = c(0.1, 0.05, 0.01), shade = c("white", "gray55", "gray 75"),las = 1,ylim = c(0.001, 25),xlim = c(-4, 4), xlab = "Effect size magitude (lnRR)", legend = TRUE)
