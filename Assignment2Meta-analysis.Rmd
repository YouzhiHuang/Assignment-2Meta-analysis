---
title: Assignment2Metaanalysis
date: "2022/10/25"
output:
 bookdown::html_document2:
    code_folding: show
    number_sections: no
    toc: yes
    toc_depth: 6
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

[My GitHub Repository](https://github.com/YouzhiHuang/Assignment-2Meta-analysis-of-Ocean-Acidification-Effects-on-Behaviour)

## **Load the necessary R Packages**

```{r loadpacks, message=FALSE, results='hide'}
# Install a load of packages that we'll use.
library(pacman)
p_load(bookdown, devtools, tidyverse, ggforce, GGally, flextable, latex2exp, png, magick, metafor, MASS, emmeans, R.rsp)
# Install the orchaRd package 
# devtools::install_github("daniel1noble/orchaRd", force = TRUE)
library(orchaRd)
library(viridis)
library(patchwork)
```
## Analysis of[Clark et al. (2020)](https://doi.org/10.1038/s41586-019-1903-y) for each of the fish speciesâ€™ `average activity` for each treatment.

```{r}
# Load data file from the data folder
path <- "./data/OA_activitydat_20190302_BIOL3207.csv"
data <- read_csv(path)
# Code to removing missing data 
comp_data <-  data %>% drop_na()
# Drop irrelevant columns
Sp_Tr <- comp_data %>% dplyr::select(-c(...1,comment,loc,animal_id,sl,size))
# Check spelling in species and treatment but also generate a summary table
unique(Sp_Tr$species)
unique(Sp_Tr$treatment)
# Use flextable to render the summary table in a tidy format
use_df_printer()
set_flextable_defaults(
  theme_fun = theme_booktabs,
  big.mark = " ", 
  font.color = "#666666",
  border.color = "#666666",
  padding = 3,
)
# Create a summary of the original dataset.
dat <- Sp_Tr %>%
  group_by(treatment,species) %>%
  summarise(n=n(),
    across(
      where(is.numeric), 
      .fns = list(
        avg = ~ mean(.x, na.rm = TRUE),
        sd = ~ sd(.x, na.rm = TRUE)
      )
    ),.groups = "drop" ) %>%
  subset(select=-c(n_avg,n_sd))
fdata <-  as_tibble(dat)
# Use flextable to render the summary table
ft <-  fdata%>%
  flextable() %>%
  separate_header() %>%
  merge_v(j = c("treatment","species")) %>%
  theme_booktabs(bold_header = TRUE)  %>% 
  valign(j = 1, valign = "top") %>%
  align(align = "center", part = "all", j = 4:5)%>%
  colformat_double(digits = 2)  %>%
  autofit()   %>%
  footnote(i = 2, j = grep("avg", colnames(fdata), value = TRUE), 
           part = "header",
           ref_symbols = " ",
            value = as_paragraph("avg: Arithmetic Mean")) %>% 
  footnote(i = 2, j = grep("sd", colnames(fdata), value = TRUE), 
           part = "header",
           ref_symbols = " ", value = as_paragraph("sd: Standard Deviation"))
ft 
```

## Merge the summary statistics generated from 1) with the metadata

```{r}
# Load data file from the data folder
matadata <- read_csv("./data/clark_paper_data.csv")
wider <- pivot_wider(fdata,names_from = treatment, values_from = c(n,activity_avg,activity_sd))
names(wider) <- c("Species","oa.n","ctrl.n","oa.mean","ctrl.mean","oa.sd","ctrl.sd")
matadatarep <- matadata[rep(seq_len(nrow(matadata)),each=6),]
meta_clark <- bind_cols(matadatarep,wider)
meta_clark
```


## merge metadata from larger meta-analysis datase

```{r}
ocean_matadata <- read_csv("./data/ocean_meta_data.csv")
oceanmatadata <- merge(x = ocean_matadata, y = meta_clark, all = TRUE)

# Rebuild the variable name avoiding spaces 
names(oceanmatadata)[3:4] <- c("Year_online","Year_print")
names(oceanmatadata)[7:10] <- c("Pub_year_IF","2017_IF","Average_n","Effect_type")
names(oceanmatadata)[12:16] <- c("Climate_FishBase","Env_cue/stimulus?","Cue/stimulus_type","Behavioural_metric","Life_stage")


# check
unique(sort(oceanmatadata$Species))

oceanmatadata$Species[oceanmatadata$Species == "acantho"] <- "Acanthochromis polyacanthus"
oceanmatadata$Species[oceanmatadata$Species == "ambon"] <- "Pomacentrus amboinensis"
oceanmatadata$Species[oceanmatadata$Species == "chromis"] <- "Chromis atripectoralis"
oceanmatadata$Species[oceanmatadata$Species == "humbug"] <- "Dascyllus aruanus"
oceanmatadata$Species[oceanmatadata$Species == "lemon"] <- "Pomacentrus moluccensis"
oceanmatadata$Species[oceanmatadata$Species == "whitedams"] <- "Dischistodus perspicillatus"


unique(sort(oceanmatadata$Species))
unique(sort(oceanmatadata$Life_stage))



```

## analyse

### 4.calculate the log response ratio (lnRR) effect size for every row

```{r}
# Exclude some NA's in sample size and r
cleanoceanmatadata <- oceanmatadata[complete.cases(oceanmatadata$ctrl.mean) & complete.cases(oceanmatadata$oa.mean)& complete.cases(oceanmatadata$ctrl.sd)& complete.cases(oceanmatadata$oa.sd)& complete.cases(oceanmatadata$ctrl.n)& complete.cases(oceanmatadata$oa.n),]

cleanInRRdata <- cleanoceanmatadata %>% filter(oa.mean/ctrl.mean >=0)

InRRdata <-  metafor::escalc(measure="ROM", m1i=oa.mean,  m2i=ctrl.mean, sd1i=oa.sd, sd2i=ctrl.sd, n1i=oa.n, n2i=ctrl.n, data=cleanInRRdata,var.names = c("lnRR", "V_lnRR"))

InRRdata

```

### meta-analytic model fitted to the data

```{r}
# Multi-level meta-analytic model
InRRdata$abslnRR <- abs(InRRdata$lnRR)
InRRdata$Observation <- rep(1:nrow(InRRdata))
#InRRdata$Study <- gsub("a"," ",InRRdata$Study)
#InRRdata
MLMA <- metafor::rma.mv(abslnRR  ~ 1, V = V_lnRR, method = "REML", random=list( ~1|Study,~1|Observation),dfs = "contain",data=InRRdata)
MLMA

```

Uncertainty in the overall meta-analysis mean: 95% confidence interval

Based on the results of our multilevel meta-analysis model, a 95% confidence interval ranging from -0.3505 to 0.0976 can be obtained. In other words, at 95%, our point estimate expects the true mean to fall between the InRR values of -0.3505 and 0.0976.


Test the null hypothesis about whether the overall meta-analytic mean is different from 0.
We can also see that the original hypothesis that lnRR is equal to 0 cannot be rejected, as 0 falls within the 95% confidence interval of the estimate, as we can see from the p-value > 0.05. To be more precise, the p-value is 0.2654.


```{r}
# Calculate I2
i2_vals <- orchaRd::i2_ml(MLMA)

# Make a pretty table. First, lets clean up the names of the different I2
# estimates. Lets remove I2_. It's a string, so, we can use some regular
# expressions to fix that. `gsub` is pretty useful. You put a pattern in and
# tell it what you would like to replace the text with. In this case, just
# blank will do! Then, we'll make the first letter of what is left
# capitalised.
i2 <- tibble(type = firstup(gsub("I2_", "", names(i2_vals))), I2 = i2_vals)


# You remember flextable. Now, lets make a pretty table. We can so some nice
# modifications here too.

flextable(i2) %>%
    align(part = "header", align = "center") %>%
    compose(part = "header", j = 1, value = as_paragraph(as_b("Type"))) %>%
    compose(part = "header", j = 2, value = as_paragraph(as_b("I"), as_b(as_sup("2")),
        as_b("(%)")))




```


```{r}
# Calculate the prediction intervals
pis <- predict(MLMA)
pis

```

Our 95% prediction interval is wide. The effect size (InRR) is expected to range from -0.659 to 0.854 in 95% replicate experiments, suggesting that there are many inconsistencies between studies.










```{r}
# Make an orchard plot using the model object
orchaRd::orchard_plot(MLMA, group = "Study", data = InRRdata,
    xlab = "Z-Transformed Correlation Coefficient (Zr)",transfm = "none")

model_results <- mod_results(MLMA, mod = "1", at = NULL, data = InRRdata, group = "Study")
model_results
# a caterpillar plot (not a caterpillars plot)
orchaRd::caterpillars(model_results, mod="Int", xlab = "Standardised mean difference") 

```

```{r}


```


## Funnel plot for visually assessing the possibility of publication bias
```{r}
# Lets make a funnel plot to visualize the data in relation to the precision,
# inverse sampling standard error,
metafor::funnel(x = InRRdata$lnRR, vi = InRRdata$V_lnRR,yaxis = "ni",digits = 2, level = c(0.1, 0.05, 0.01),shade = c("white", "gray55", "gray 75"),las = 1, xlab = "Correlation Coefficient (r)",legend=TRUE)


funnel<-ggplot(InRRdata,aes(x=lnRR, y=Average_n, color=Study))+
  geom_point(size=2,alpha=0.6)+ 
  scale_color_viridis(discrete=TRUE)+ 
  xlab("Effect size magitude (lnRR)")+
  ylab("Mean sample size")+
  scale_x_continuous(breaks = round(seq(min(InRRdata$lnRR), max(InRRdata$lnRR), by = 1),0))+
  scale_y_continuous(breaks = round(seq(0, 600, by = 50),1))+
  theme(legend.position = "NONE")+
  geom_vline(xintercept =0,linetype="dashed",color="red")+
  theme_bw(12)+
  theme(legend.position = "NONE")+ 
  theme(panel.grid.minor = element_blank())

funnel


```





```{r}
ggplot(InRRdata, aes(y = lnRR, x = V_lnRR)) + geom_point() + geom_smooth(method = lm) +
    labs(y = "Fisher's Z-transformed Correlation Coefficient (Zr)", x = "Sampling Variance of Zr") +
    theme_classic()


```


Time-lag plot assessing how effect sizes may or may not have changed through time.
```{r}
Time_lag <- ggplot(InRRdata, aes(y = abslnRR, x = Year_online, color=Study)) + 
    geom_smooth(aes(alpha=0.05),method = "loess",se=TRUE, fullrange=TRUE, level=0.95, color="black",show.legend = T)+
   geom_point(size=InRRdata$Average_n*0.03,alpha = 0.3) +
  #scale_size(range = c(1, 2), name="Sample size")+ 
  scale_color_viridis(discrete=TRUE)+ 
   geom_hline(yintercept =0,linetype="dashed",color="red")+
  xlab("Year")+ylab("Effect size magnitude (lnRR)")+
scale_x_continuous(breaks = round(seq(min(InRRdata$Year_online), max(InRRdata$Year_online), by = 1),1))+
  scale_y_continuous(breaks = round(seq(min(InRRdata$lnRR), 15, by = 2),0)) + theme_minimal(12)+
  theme(legend.position = "none")
Time_lag

```


## Formal meta-regression model that includes year as a moderator (fixed effect) to test for time-lag bias


```{r}
metareg_v <- rma.mv(lnRR ~ V_lnRR, V = V_lnRR, random = list(~1 |Study, ~1 | Observation),
    test = "t", dfs = "contain", data = InRRdata)
summary(metareg_v)

r2 <- orchaRd::r2_ml(metareg_v)
r2

```


```{r}
# Including sampling variance as moderator
metareg_time <- rma.mv(lnRR ~ Year_online, V = V_lnRR, random = list(~1 |Study, ~1 | Observation),
    test = "t", dfs = "contain", data = InRRdata)
summary(metareg_time)

```

```{r}
# How much variation does time when results were published explain in Zr?
r2_time <- orchaRd::r2_ml(metareg_time)  #'ADD YOUR CODE HERE'
r2_time
```


```{r}
# Including sampling variance as moderator
metareg_time1 <- rma.mv(abslnRR ~ Year_online, V = V_lnRR, random = list(~1 |Study, ~1 | Observation),
    test = "t", dfs = "contain", data = InRRdata)
summary(metareg_time1)
r2_time1 <- orchaRd::r2_ml(metareg_time1)  #'ADD YOUR CODE HERE'
r2_time1
```


## 10 Formal meta-regression model that includes inverse sampling variance (i.e., 1vlnRR) to test for file-drawer biases

```{r}
# Including sampling variance and year as moderators to account for both!
metareg_time2 <- rma.mv(abslnRR ~ Year_online + V_lnRR,  V = V_lnRR,random = list(~1 |Study, ~1 | Observation),
    test = "t", dfs = "contain", data = InRRdata)
summary(metareg_time2)
r2_time2 <- orchaRd::r2_ml(metareg_time2)  #'ADD YOUR CODE HERE'
r2_time2

```

```{r}
InRRdata <- InRRdata %>%
    mutate(Year_c = Year_online - mean(Year_online))  # 'ADD YOUR CODE HERE'
# Including sampling variance and mean centered year as moderators to account
# for both!
metareg_time_c <- rma.mv(abslnRR ~ Year_c + V_lnRR,  V = V_lnRR,random = list(~1 |Study, ~1 | Observation),
    test = "t", dfs = "contain", data = InRRdata)
summary(metareg_time_c)  # 'ADD YOUR CODE HERE'


```

## 11 A written paragraph that discusses the potential for publication bias based on the meta-regression results. What type of publication bias, if any, appears to be present in the data? If publication bias is present, what does it mean and what might be contributing to such bias?



## 12 Identify any studies contributing to publication bias. How do your updated meta-analysis results compare with a meta-analysis by Clement et. al. (2022)? Are there any concerns about these studies? If so, describe using references to existing papers what concerns have been raised?









